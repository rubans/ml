{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b2b4b7-d95e-46bc-be4d-f273ef082d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# google_cloud_pipeline_components includes pre-built KFP components for interfacing with Vertex AI services.\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google.cloud import aiplatform as vertexai\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fdd7be-3f09-479f-8ce8-2c80afb5ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"fast-planet-243821\"\n",
    "REGION = \"us-central1\"\n",
    "GCS_BUCKET = f\"gs://{PROJECT_ID}_pipeline-artifacts\"\n",
    "TIMESTAMP=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "DISPLAY_NAME = \"cifar-{}\".format(TIMESTAMP)\n",
    "MODEL_DIR = \"image-estimator\"\n",
    "MODEL_DISPLAY_NAME = \"image-estimator-{}\".format(TIMESTAMP)\n",
    "GCS_BASE_OUTPUT_DIR= f\"{GCS_BUCKET}/{MODEL_DIR}-{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186c88c3-f8b5-45b4-94ce-d501549e7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"tensorflow\",\"tensorflow_datasets\"]\n",
    ")\n",
    "def train_cifar_model(output_model_uri: str) -> str:\n",
    "    ##import subprocess\n",
    "    ## Install dependencies from requirements.txt\n",
    "    #subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "    \n",
    "    import tensorflow_datasets as tfds\n",
    "    import tensorflow as tf\n",
    "    print(f\"input: {output_model_uri}\")\n",
    "    # Your training code here\n",
    "    # Use the provided notebook code or replace with your custom training logic\n",
    "    BUFFER_SIZE = 10000\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(output_model_uri + '/checkpoint',\n",
    "                                                             save_freq='epoch')\n",
    "\n",
    "    def scale(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.0\n",
    "        return image, label\n",
    "\n",
    "    datasets, info = tfds.load(name='cifar10', with_info=True, as_supervised=True)\n",
    "    train_dataset = datasets['train'].map(scale).shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
    "\n",
    "    model.fit(x=train_dataset, epochs=10, steps_per_epoch=200,\n",
    "              callbacks=[checkpoint_callback])\n",
    "    model.save(output_model_uri)\n",
    "    return output_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb5294f-53b4-4241-a2f4-70706a877cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def upload_model_to_vertex(model_uri: str, project: str, region: str, model_display_name: str) -> str:\n",
    "    # Upload the trained model to Vertex AI\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    aiplatform.init(project=project, location=region)\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_display_name,\n",
    "        artifact_uri=model_uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest\",\n",
    "    )\n",
    "\n",
    "    print(f\"Model uploaded to Vertex AI: {model.resource_name}\")\n",
    "    return model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53248af3-5c9f-4466-9dce-d3311359d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def deploy_model_to_endpoint(model_uri: str, project: str, region: str, endpoint_display_name: str) -> str:\n",
    "    # Deploy the model to a Vertex AI endpoint\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    aiplatform.init(project=project, location=region)\n",
    "    model = aiplatform.Model(model_name=model_uri, project=project)\n",
    "    endpoint = model.deploy()\n",
    "    \n",
    "    print(f\"Model deployed to Vertex AI endpoint: {endpoint.resource_name}\")\n",
    "    return endpoint.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c5f2ef-abe2-42b7-a465-cf592f83b8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {{pipelineparam:op=;name=output_model_uri}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "    name=\"cifar-model-training\",\n",
    "    description=\"A pipeline for training a CIFAR model and deploying it to Vertex AI.\",\n",
    ")\n",
    "def cifar_pipeline(\n",
    "    output_model_uri: str,\n",
    "    project: str,\n",
    "    region: str,\n",
    "    model_display_name: str,\n",
    "    endpoint_display_name: str,\n",
    "    requirements_file_path:str = 'requirements.txt',\n",
    "):\n",
    "    print(f\"input: {output_model_uri}\")\n",
    "    train_task = train_cifar_model(output_model_uri)\n",
    "    upload_task = upload_model_to_vertex(train_task.output, project, region, model_display_name)\n",
    "    deploy_task = deploy_model_to_endpoint(upload_task.output, project, region, endpoint_display_name)\n",
    "\n",
    "# Compile the pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=cifar_pipeline,\n",
    "    package_path='cifar_pipeline_job.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a889b4-d8fc-44d1-9fcd-493852c9703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI client\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be393b21-13d4-4cc3-87b0-ae13a4710825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify pipeline parameters\n",
    "pipeline_params = {\n",
    "    \"output_model_uri\": GCS_BASE_OUTPUT_DIR,\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"region\": REGION,\n",
    "    \"model_display_name\": MODEL_DISPLAY_NAME,\n",
    "    \"endpoint_display_name\": MODEL_DISPLAY_NAME,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40c89a5-8d70-4e7d-98ec-edf4b0f8e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/cifar-model-training-20231208215153?project=515007598211\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/515007598211/locations/us-central1/pipelineJobs/cifar-model-training-20231208215153\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline run\n",
    "job = vertexai.PipelineJob(\n",
    "    display_name=\"cifar-pipeline-job\",\n",
    "    template_path=f\"cifar_pipeline_job.json\",\n",
    "    parameter_values=pipeline_params,\n",
    ")\n",
    "# Run the pipeline and wait for completion\n",
    "job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6072c-36bd-4b9c-9015-9ad48223faf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
