{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pip dependenices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat==0.4.2 in c:\\users\\ruban\\appdata\\roaming\\python\\python311\\site-packages (0.4.2)\n",
      "Requirement already satisfied: autogen-core==0.4.2 in c:\\users\\ruban\\appdata\\roaming\\python\\python311\\site-packages (from autogen-agentchat==0.4.2) (0.4.2)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (1.29.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=4.25.1 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (4.25.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (2.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\python311\\lib\\site-packages (from autogen-core==0.4.2->autogen-agentchat==0.4.2) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\python311\\lib\\site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\python311\\lib\\site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\python311\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\python311\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.2->autogen-agentchat==0.4.2) (3.21.0)\n",
      "Requirement already satisfied: PyMuPDF in c:\\python311\\lib\\site-packages (1.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install autogen-agentchat==0.4.2 --user\n",
    "!pip install PyMuPDF --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "pdf_path = \"original/outlier-or-laggard-divergence-and-convergence-in-the-uks-recent-inflation-performance.pdf\"\n",
    "output_dir = \"output/PyMuPDF/outlier-or-laggard-divergence-and-convergence-in-the-uks-recent-inflation-performance/\"\n",
    "# Configure Google Cloud project\n",
    "PROJECT_ID = \"cryptic-skyline-411516\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing page_1..\n",
      "processing page_2..\n",
      "processing page_3..\n",
      "processing page_4..\n",
      "processing page_5..\n",
      "processing page_6..\n",
      "processing page_7..\n",
      "processing page_8..\n",
      "processing page_9..\n",
      "processing page_10..\n",
      "processing page_11..\n",
      "processing page_12..\n",
      "processing page_13..\n",
      "processing page_14..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from typing import AsyncGenerator, List, Sequence, Tuple\n",
    "\n",
    "from autogen_agentchat.agents import BaseChatAgent\n",
    "from autogen_agentchat.base import Response\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage, TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "# define custom agent - convert pdf to pngs\n",
    "class ConverPDFAgent(BaseChatAgent):\n",
    "    def __init__(self, name: str, input_path: str, output_path: str, zoom: float=2.0):\n",
    "        super().__init__(name, \"An agent that convers PDFs to Images.\")\n",
    "        self._input_path = input_path\n",
    "        self._output_path = output_path\n",
    "        self._zoom = zoom\n",
    "\n",
    "    @property\n",
    "    def produced_message_types(self) -> Sequence[type[ChatMessage]]:\n",
    "        return (TextMessage,)\n",
    "\n",
    "    async def on_messages(self, messages: Sequence[ChatMessage], cancellation_token: CancellationToken) -> Response:\n",
    "        # Calls the on_messages_stream.\n",
    "        response: Response | None = None\n",
    "        async for message in self.on_messages_stream(messages, cancellation_token):\n",
    "            if isinstance(message, Response):\n",
    "                response = message\n",
    "        assert response is not None\n",
    "        return response\n",
    "\n",
    "    async def on_messages_stream(\n",
    "        self, messages: Sequence[ChatMessage], cancellation_token: CancellationToken\n",
    "    ) -> AsyncGenerator[AgentEvent | ChatMessage | Response, None]:\n",
    "        inner_messages: List[AgentEvent | ChatMessage] = []\n",
    "        # for i in range(self._count, 0, -1):\n",
    "        #     msg = TextMessage(content=f\"{i}...\", source=self.name)\n",
    "        #     inner_messages.append(msg)\n",
    "        #     yield msg\n",
    "        with fitz.open(self._input_path) as pdf_document:\n",
    "            if not os.path.exists(self._output_path):\n",
    "                os.makedirs(self._output_path)\n",
    "            # Loop through each page in the PDF\n",
    "            for page_num in range(len(pdf_document)):\n",
    "                page = pdf_document[page_num]\n",
    "                # Zoom factor: higher zoom increases resolution\n",
    "                mat = fitz.Matrix(self._zoom, self._zoom)\n",
    "                pix = page.get_pixmap(matrix=mat)  # Render page to an image\n",
    "                # Save the image\n",
    "                output_file = os.path.join(self._output_path, f\"page_{page_num + 1}.png\")\n",
    "                pix.save(output_file)\n",
    "                msg = TextMessage(content=f\"processing page_{page_num + 1}..\", source=self.name)\n",
    "                inner_messages.append(msg)\n",
    "                yield msg\n",
    "        yield Response(chat_message=TextMessage(content=\"Done!\", source=self.name), inner_messages=inner_messages)\n",
    "\n",
    "    async def on_reset(self, cancellation_token: CancellationToken) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "async def run_countdown_agent() -> None:\n",
    "    # Create a countdown agent.\n",
    "    countdown_agent = ConverPDFAgent(\"countdown\",pdf_path,output_dir)\n",
    "    # Run the agent with a given task and stream the response.\n",
    "    async for message in countdown_agent.on_messages_stream([], CancellationToken()):\n",
    "        if isinstance(message, Response):\n",
    "            print(message.chat_message.content)\n",
    "        else:\n",
    "            print(message.content)\n",
    "\n",
    "\n",
    "# Use asyncio.run(run_countdown_agent()) when running in a script.\n",
    "await run_countdown_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarise image...\n",
      "total_tokens:  total_tokens: 262\n",
      "total_billable_characters: 18\n",
      "\n",
      "prompt_token_count: 262\n",
      "candidates_token_count: 280\n",
      "total_token_count: 542\n",
      "\n",
      "Gemini's response: This image contains two charts from a Bank of England report, focusing on inflation and pay growth. \n",
      "\n",
      "\n",
      "**Chart 5:** This line chart shows the one-year-ahead inflation expectations from three sources (Bank/Ipsos, Citi/YouGov, and Decision Maker Panel) from 2008 to 2024.  The chart highlights a significant drop in inflation expectations from mid-2022 to early 2024. Dashed lines indicate the average inflation expectations from 2006 to 2019.\n",
      "\n",
      "\n",
      "**Chart 6:** This stacked bar chart displays the components of private sector regular pay growth from 2018 to 2024. The components include: inflation expectations, productivity, unexplained factors (residual), and slack. The chart shows a decline in pay growth from 2023 to 2024, accompanied by the decrease in inflation expectations. \n",
      "\n",
      "\n",
      "**Overall Report Narrative:** The report uses these charts to illustrate the Bank of England's argument that easing inflation expectations are a key factor in slowing pay growth. The charts visually demonstrate this relationship by showing a parallel decrease in inflation expectations and pay growth.  The report also points to other factors influencing pay growth (productivity, slack, etc.).  The footnotes provide detailed methodologies for calculating the data presented in the charts.\n",
      "\n",
      "summarise pdf...\n",
      "total_tokens:  total_tokens: 3624\n",
      "total_billable_characters: 40\n",
      "\n",
      "prompt_token_count: 3624\n",
      "candidates_token_count: 629\n",
      "total_token_count: 4253\n",
      "\n",
      "Gemini's response: The PDF contains a speech by Dave Ramsden, Deputy Governor of the Bank of England, given at the Peterson Institute for International Economics on April 19, 2024.  The speech discusses the UK's recent inflation performance, comparing it to that of the US and Eurozone.\n",
      "\n",
      "Here's a summary of the charts included:\n",
      "\n",
      "* **Chart 1:** Shows inflation rates in the UK, US, and Euro area from January 2022 to January 2024.  The UK experienced higher inflation than the US and Euro area, particularly in the latter half of 2023.\n",
      "\n",
      "* **Chart 2:** Illustrates interest rates in the UK, US, and Euro area during the same period.  The UK Bank Rate increased significantly more than the others in the summer of 2023.\n",
      "\n",
      "* **Chart 3:** Presents a decomposition of headline inflation for the UK, US, and Euro area, breaking down the contribution of different components (services, core goods, food, energy).  This highlights the significant role of energy prices in driving inflation in the UK and Euro area, less so in the US.\n",
      "\n",
      "* **Chart 4:** Shows the feedthrough of external inflationary pressures (energy, food, core goods) on headline inflation.  Illustrates how the contribution of these factors has fallen significantly by the beginning of 2024.\n",
      "\n",
      "* **Chart 5:** Displays the evolution of one-year-ahead inflation expectations as measured by various surveys (Bank/Ipsos, Citi/YouGov, and Decision Maker Panel) which demonstrates a decline in expectations as headline inflation falls.\n",
      "\n",
      "* **Chart 6:** Shows the easing of inflationary pressures as a key driver in weakening pay growth in the UK's private sector.\n",
      "\n",
      "* **Chart 7:** Presents the UK's vacancies-to-unemployment ratio, indicating a loosening in the labor market.\n",
      "\n",
      "* **Chart 8:** Shows projections for private sector regular average weekly earnings growth, highlighting the divergence between actual growth and the predictions of models.\n",
      "\n",
      "* **Chart 9:** Illustrates the evolution of services inflation in the UK, comparing outturns to short-term forecasts.  Indicates a decline in services inflation.\n",
      "\n",
      "* **Chart 10:** Provides a decomposition of underlying services inflation, showing the contributions from pay growth and producer prices.\n",
      "\n",
      "* **Chart 11:** Compares 12-month services inflation rates in the UK, US, and Euro area, again emphasizing the UK's relatively high inflation.\n",
      "\n",
      "* **Chart 12:** Shows 3-month annualised run-rates for services inflation in the UK, US, and Euro area, demonstrating convergence of the UK with the others.\n",
      "\n",
      "\n",
      "In essence, the charts visually support Ramsden's argument that while the UK was an outlier in its inflation performance earlier, it's now catching up with other advanced economies as disinflationary pressures take hold.  However, the UK's labor market remains relatively tight compared to other countries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import UserProxyAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "import autogen\n",
    "import vertexai\n",
    "import traceback\n",
    "import base64\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image\n",
    "\n",
    "# Initialize Vertex AI client\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "# Function to encode image to base64\n",
    "def encode_image(image_path):\n",
    "    print(\"encoding...\")\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "from pathlib import Path\n",
    "def encode_pdf(pdf_path):\n",
    "    return Path(pdf_path).read_bytes()\n",
    "\n",
    "# Function to call Vertex AI Gemini for image-to-text summarization\n",
    "async def call_vertex_gemini_document_to_text(doc_path: str, mime_type: str = None) -> str:\n",
    "    try:\n",
    "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "        if(mime_type == \"application/pdf\"):\n",
    "            print(\"summarise pdf...\")            \n",
    "            encoded=encode_pdf(doc_path)\n",
    "            #print(\"encoded\", base64.b64decode(encoded))\n",
    "            attachment_file =  Part.from_data( mime_type=\"application/pdf\",\n",
    "                                    data=encoded)\n",
    "            prompt = \"Can you  summarise images from the attached pdf?\"\n",
    "        else:\n",
    "            print(\"summarise image...\")  \n",
    "            attachment_file = Part.from_image(Image.load_from_file(doc_path))\n",
    "            prompt = \"Describe this image?\"\n",
    "        # Query the model\n",
    "        \n",
    "        print(\"total_tokens: \", model.count_tokens([attachment_file, prompt]))\n",
    "        response = model.generate_content([attachment_file, prompt])\n",
    "        print(response.usage_metadata)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return f\"Error calling Vertex AI: {str(e)}\"\n",
    "\n",
    "# Custom UserProxyAgent to interact with Gemini\n",
    "class GeminiUserProxyAgent(UserProxyAgent):\n",
    "    def __init__(self, name: str, input_path: str, mime_type : str = None):\n",
    "        super().__init__(name=name, description=\"An agent that converts images to text.\")\n",
    "        self._input_path = input_path\n",
    "        self._mime_type = mime_type\n",
    "        \n",
    "    async def on_messages(self, cancellation_token: CancellationToken):\n",
    "        # Call Gemini using the Google Cloud SDK\n",
    "        gemini_response = await call_vertex_gemini_document_to_text(doc_path=self._input_path, mime_type=self._mime_type)\n",
    "        # Return the generated response from Gemini\n",
    "        return TextMessage(content=gemini_response, source=\"gemini\")\n",
    "\n",
    "# Main function to run the agent\n",
    "async def document_summary_agent(input_path: str, mime_type: str = None):\n",
    "    agent = GeminiUserProxyAgent(name=\"image_summariser\", input_path=input_path, mime_type=mime_type)\n",
    "    # User's input message\n",
    "    user_message = TextMessage(content=\"Summarise attached message?\", source=\"user\")\n",
    "    # Send the message and get the response from Gemini\n",
    "    response = await agent.on_messages(\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    \n",
    "    print(f\"Gemini's response: {response.content}\")\n",
    "\n",
    "# Run the async function\n",
    "await document_summary_agent(output_dir+\"//page_8.png\")\n",
    "await document_summary_agent(\"C:\\\\Code\\\\ml\\\\playground\\\\original\\\\outlier-or-laggard-divergence-and-convergence-in-the-uks-recent-inflation-performance.pdf\",\"application/pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
